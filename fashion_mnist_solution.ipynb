{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fashion_mnist_solution.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPVjVyLPbmk+zdjfcZt5OVD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mett29/optimized-fashion-mnist/blob/main/fashion_mnist_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6_tWIE_ud8Z"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BL-X_PjLuMy5",
        "outputId": "b3cb4235-4e01-4939-a15c-79965fb0876b"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import tempfile\n",
        "\n",
        "!pip install tensorflow-model-optimization\n",
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "print(f'Tensorflow version: {tf.__version__}')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-model-optimization\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/38/4fd48ea1bfcb0b6e36d949025200426fe9c3a8bfae029f0973d85518fa5a/tensorflow_model_optimization-0.5.0-py2.py3-none-any.whl (172kB)\n",
            "\r\u001b[K     |██                              | 10kB 21.2MB/s eta 0:00:01\r\u001b[K     |███▉                            | 20kB 15.0MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 30kB 9.4MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 40kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 51kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 61kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 71kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 81kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 92kB 6.0MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 102kB 6.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 112kB 6.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 122kB 6.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 133kB 6.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 143kB 6.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 153kB 6.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 163kB 6.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 174kB 6.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization) (0.1.6)\n",
            "Requirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization) (1.19.5)\n",
            "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization) (1.15.0)\n",
            "Installing collected packages: tensorflow-model-optimization\n",
            "Successfully installed tensorflow-model-optimization-0.5.0\n",
            "Tensorflow version: 2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNUG7aO0urH7"
      },
      "source": [
        "## Baseline model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4R3Zw1arutad",
        "outputId": "eaf828b5-66ec-4084-fda8-1c9a60aaa6fb"
      },
      "source": [
        "# Load the dataset.\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "# Normalize\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Add a trailing unitary dimension to make a 3D multidimensional array (tensor).\n",
        "# N x 28 x 28 --> N x 28 x 28 x 1\n",
        "train_images = np.expand_dims(train_images, -1)\n",
        "test_images = np.expand_dims(test_images, -1)\n",
        "\n",
        "# Convert the labels from integers to one-hot encoding.\n",
        "train_labels = tf.keras.utils.to_categorical(train_labels, 10)\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels, 10)\n",
        "\n",
        "LR = 1E-3 \n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "def build_model(input_shape):\n",
        "    model = tf.keras.models.Sequential()\n",
        "\n",
        "    model.add(tf.keras.layers.InputLayer(input_shape=input_shape))\n",
        "    model.add(tf.keras.layers.Conv2D(32, (5, 5), padding='same', activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "    model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(64, (5, 5), padding='same', activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(128, (5, 5), padding='same', activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "    model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(128))\n",
        "    model.add(tf.keras.layers.Activation('elu'))\n",
        "    model.add(tf.keras.layers.Dropout(0.5))\n",
        "    model.add(tf.keras.layers.Dense(10))\n",
        "    model.add(tf.keras.layers.Activation('softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "def train(train_images, train_labels):\n",
        "    \"\"\"\n",
        "    Train the model given the dataset and the global parameters (LR, EPOCHS and BATCH_SIZE).\n",
        "    The model is automalically saved after the training.\n",
        "\n",
        "    \"\"\"\n",
        "    model = build_model(train_images.shape[1:])\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=LR),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['categorical_accuracy'],\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    model.fit(\n",
        "        x=train_images.astype(np.float32),\n",
        "        y=train_labels.astype(np.float32),\n",
        "        epochs=EPOCHS,\n",
        "        batch_size=BATCH_SIZE,\n",
        "    )\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(\"Train elapsed time: {} seconds\".format(end_time - start_time))\n",
        "\n",
        "    model.save(\"baseline_model.tf\", overwrite=True)    \n",
        "\n",
        "\n",
        "def test(test_images, test_labels, model_path):\n",
        "    \"\"\"\n",
        "    Load the saved model and evaluate it against the test set.\n",
        "    \"\"\"\n",
        "    model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "    print(\"Test Loss: {} - Test Accuracy: {}\".format(test_loss, test_acc))\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(\"Test elapsed time: {} seconds\".format(end_time - start_time))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGCAI_rNvMUh"
      },
      "source": [
        "Train the baseline model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uH1j5R7vB2m",
        "outputId": "168498b2-2160-4b40-dce9-b24c074f6c2c"
      },
      "source": [
        "train(train_images, train_labels)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "938/938 [==============================] - 37s 8ms/step - loss: 0.5443 - categorical_accuracy: 0.8028\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 0.3431 - categorical_accuracy: 0.8751\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 0.3046 - categorical_accuracy: 0.8901\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 0.2809 - categorical_accuracy: 0.8971\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 0.2617 - categorical_accuracy: 0.9046\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 0.2511 - categorical_accuracy: 0.9081\n",
            "Epoch 7/10\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 0.2399 - categorical_accuracy: 0.9122\n",
            "Epoch 8/10\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 0.2312 - categorical_accuracy: 0.9154\n",
            "Epoch 9/10\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 0.2239 - categorical_accuracy: 0.9171\n",
            "Epoch 10/10\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.2195 - categorical_accuracy: 0.9180\n",
            "Train elapsed time: 100.33633255958557 seconds\n",
            "INFO:tensorflow:Assets written to: baseline_model.tf/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAklF43mvO3S"
      },
      "source": [
        "Evaluate the baseline model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lovRgIgLvIme",
        "outputId": "ffef865a-b80f-4751-851b-11b818550c28"
      },
      "source": [
        "model_path = \"./baseline_model.tf\"\n",
        "test(test_images, test_labels, model_path)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 4ms/step - loss: 0.2489 - categorical_accuracy: 0.9112\n",
            "Test Loss: 0.2488774210214615 - Test Accuracy: 0.9111999869346619\n",
            "Test elapsed time: 1.4511198997497559 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfxI0RixvU25"
      },
      "source": [
        "## Weight Pruning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRLVfEs3vWvK",
        "outputId": "47aacbf5-271a-45f6-aefa-919473194929"
      },
      "source": [
        "def apply_pruning_to_dense(layer):\n",
        "  if isinstance(layer, tf.keras.layers.Dense):\n",
        "    return tfmot.sparsity.keras.prune_low_magnitude(layer)\n",
        "  return layer\n",
        "\n",
        "# Load the baseline\n",
        "model = tf.keras.models.load_model(\"./baseline_model.tf\")\n",
        "\n",
        "# Compute end step to finish pruning after 2 epochs.\n",
        "batch_size = 64\n",
        "epochs = 2\n",
        "validation_split = 0.1 # 10% of training set will be used for validation set.\n",
        "\n",
        "# Use `tf.keras.models.clone_model` to apply `apply_pruning_to_dense`  to the layers of the model.\n",
        "model_for_pruning = tf.keras.models.clone_model(\n",
        "    model,\n",
        "    clone_function=apply_pruning_to_dense,\n",
        ")\n",
        "\n",
        "model_for_pruning.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LR),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['categorical_accuracy'],\n",
        ")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:2191: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hq7DJ6zhvvrl"
      },
      "source": [
        "Fine-tune model for pruning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCrmjSUEvzqF",
        "outputId": "ecd886e3-2f90-4a5e-b9e2-a1cfdeabd58e"
      },
      "source": [
        "logdir = tempfile.mkdtemp()\n",
        "\n",
        "callbacks = [\n",
        "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
        "]\n",
        "\n",
        "model_for_pruning.fit(train_images.astype(np.float32), train_labels.astype(np.float32),\n",
        "                  batch_size=BATCH_SIZE, epochs=epochs, validation_split=validation_split, callbacks=callbacks)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
            "  3/844 [..............................] - ETA: 2:50 - loss: 0.2048 - categorical_accuracy: 0.9323WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0078s vs `on_train_batch_begin` time: 0.0280s). Check your callbacks.\n",
            "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0078s vs `on_train_batch_end` time: 0.0389s). Check your callbacks.\n",
            "844/844 [==============================] - 11s 11ms/step - loss: 0.2198 - categorical_accuracy: 0.9205 - val_loss: 0.1580 - val_categorical_accuracy: 0.9415\n",
            "Epoch 2/2\n",
            "844/844 [==============================] - 8s 10ms/step - loss: 0.2051 - categorical_accuracy: 0.9246 - val_loss: 0.1802 - val_categorical_accuracy: 0.9317\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f90fca945d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S39deB9qwFds"
      },
      "source": [
        "Evaluate the weight pruned model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Q3WLG5Sv_Xo",
        "outputId": "37a0fc85-b4bc-4f95-e905-bbe3901a8cce"
      },
      "source": [
        "_, model_for_pruning_accuracy = model_for_pruning.evaluate(test_images, test_labels, verbose=0)\n",
        "print(\"Weight pruned model test accuracy: {}\".format(model_for_pruning_accuracy))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Weight pruned model test accuracy: 0.9139999747276306\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4hTP8OyweD_"
      },
      "source": [
        "Save the weight pruned model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PLA01d2wS5i",
        "outputId": "dd6c1d8d-480d-493b-c5f6-98c3c67f4595"
      },
      "source": [
        "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning) # Necessary step to see the benefits of the pruning\n",
        "model_for_export.save(\"weight_pruned_model.tf\", overwrite=True)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "INFO:tensorflow:Assets written to: weight_pruned_model.tf/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_QVQmnBwmo7"
      },
      "source": [
        "Convert to TFLite"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CU_SmDfSwpB6"
      },
      "source": [
        "def convert_to_tflite(saved_model_dir, output_filename, use_quantization=False):\n",
        "  # Convert the model\n",
        "  converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir) # path to the SavedModel directory\n",
        "  if use_quantization:\n",
        "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "  tflite_model = converter.convert()\n",
        "\n",
        "  # Save the model\n",
        "  with open(output_filename + '.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "  return tflite_model\n",
        "\n",
        "def get_gzipped_model_size(file):\n",
        "  # Returns size of gzipped model, in bytes.\n",
        "  import os\n",
        "  import zipfile\n",
        "\n",
        "  _, zipped_file = tempfile.mkstemp('.zip')\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(file)\n",
        "\n",
        "  return os.path.getsize(zipped_file) / float(2**20)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXRlfVqowtd7"
      },
      "source": [
        "Convert the model and apply quantization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQaJqRgYwt2R"
      },
      "source": [
        "output_filename = \"weight_pruned_and_quantized_model\"\n",
        "weight_pruned_tflite_model = convert_to_tflite(\"./weight_pruned_model.tf\", output_filename, use_quantization=True)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvWAlrHYxb84"
      },
      "source": [
        "Convert also the baseline model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sL8RBOFhxbOc"
      },
      "source": [
        "output_filename = \"baseline_model\"\n",
        "baseline_tflite_model = convert_to_tflite(\"./baseline_model.tf\", output_filename)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXSz0rwUw3Z7"
      },
      "source": [
        "Compare the size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5kBTOj8xEnP",
        "outputId": "afe9b742-7727-4c47-abb5-82123a45190f"
      },
      "source": [
        "print(\"Size of gzipped baseline tflite model: %.2f MB\" % (get_gzipped_model_size(\"./baseline_model.tflite\")))\n",
        "print(\"Size of gzipped weight pruned and quantized tflite model: %.2f MB\" % (get_gzipped_model_size(\"./weight_pruned_and_quantized_model.tflite\")))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of gzipped baseline tflite model: 1.44 MB\n",
            "Size of gzipped weight pruned and quantized tflite model: 0.32 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJabqVCRxrhl"
      },
      "source": [
        "## Check persistency of accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylsasuiWxvWa"
      },
      "source": [
        "def evaluate_model(interpreter):\n",
        "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "\n",
        "  # Run predictions on ever y image in the \"test\" dataset.\n",
        "  prediction_digits = []\n",
        "  for i, test_image in enumerate(test_images):\n",
        "    if i % 1000 == 0:\n",
        "      print('Evaluated on {n} results so far.'.format(n=i))\n",
        "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
        "    # the model's input data format.\n",
        "    test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
        "    interpreter.set_tensor(input_index, test_image)\n",
        "\n",
        "    # Run inference.\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # Post-processing: remove batch dimension and find the digit with highest\n",
        "    # probability.\n",
        "    output = interpreter.tensor(output_index)\n",
        "    digit = np.argmax(output()[0])\n",
        "    prediction_digits.append(digit)\n",
        "\n",
        "  print('\\n')\n",
        "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
        "  prediction_digits = np.array(prediction_digits)\n",
        "  # Revert from categorical to numerical\n",
        "  test_labels_numerical = np.argmax(test_labels, axis=-1)\n",
        "  accuracy = (prediction_digits == test_labels_numerical).mean()\n",
        "  return accuracy"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-bKWmFTyD2_"
      },
      "source": [
        "Note that it will take some time because of the quantization, which, as explained in the documentation, seems to slow down the inference time on desktop CPUs/GPUs. It is instead beneficial in a mobile setting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXvoBEX_x0w9",
        "outputId": "2c834118-9562-4349-f4ef-2af9ea180410"
      },
      "source": [
        "interpreter = tf.lite.Interpreter(model_content=weight_pruned_tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "test_accuracy = evaluate_model(interpreter)\n",
        "\n",
        "print('Weight pruned and quantized TFLite test accuracy:', test_accuracy)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluated on 0 results so far.\n",
            "Evaluated on 1000 results so far.\n",
            "Evaluated on 2000 results so far.\n",
            "Evaluated on 3000 results so far.\n",
            "Evaluated on 4000 results so far.\n",
            "Evaluated on 5000 results so far.\n",
            "Evaluated on 6000 results so far.\n",
            "Evaluated on 7000 results so far.\n",
            "Evaluated on 8000 results so far.\n",
            "Evaluated on 9000 results so far.\n",
            "\n",
            "\n",
            "Weight pruned and quantized TFLite test accuracy: 0.9138\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}